Who’s ready for more World War Two science?
No? No one?

Well, this story is about all kinds of badness,
yes—but also a lot of incredible goodness.

The history of science up until the Cold War
is often overshadowed by the Manhattan Project.

But today we are going to talk about advances
in biomedicine, or healthcare based on a biological

understanding of human bodies and diseases.

[Intro Music Plays]

Many biomedical breakthroughs, like antibiotics,
were developed in the twentieth century, but

a few are much older.
The original wonder drug is a natural pain-relief

compound of the opiate class that is still
widely used today—morphine.

A German pharmacist’s assistant named Friedrich
Sertürner isolated it around 1804.

Morphine induces relaxation and sleepiness,
and too much can kill you. Aaaaand it’s

super addictive. But very effective and relatively
cheap!

Soon, a German company called Merck began
selling it. And in the 1850s, the hypodermic

needle was introduced.
Now, the last time we talked about medicine,

exciting things were happening: namely, germs!
Most diseases are caused by germs.

So, with a germ theory—not to mention a
cell theory, and vaccines, and beer—the

life sciences in the late 1800s looked pretty
great.

But… vaccines are slow, so if you’re dying
right now—maybe due to an infected war-wound—they

don’t work well.
And, they only work on certain diseases. Also,

there just weren’t that many vaccines, and
there were a lot of diseases. In fact, even

reliable diagnoses were a problem.
So what the life sciences had gained in theories

and models, they still lacked in applications.
Advances came in the form of chemical compounds

that had specific effects on specific physiological
systems.

In 1907, the lab of German chemist Paul Ehrlich
created an arsenic compound sold under the

name Salvarsan that was antimicrobial but
not toxic to humans.

Ehrlich used Salvarsan to effectively treat
syphilis, which was a huge deal: the first

modern chemical therapeutic could treat one
of the biggest public health problems!

But Salvarsan didn’t work on late-stage
syphilis patients who suffered from general

paresis of the insane, or GPI. Which had very
serious symptoms, including delusions, and

was fatal.
But in 1917, Austrian physician Julius Wagner-Jauregg

developed an effective therapy… which involved
infecting them with malaria. While weird,

malaria-fever treatment for GPI gave hope
to people suffering terribly, and Wagner-Jauregg

won a Nobel for his efforts.
Another psychiatric discovery, in 1933, was

insulin shock therapy to treat schizophrenia
and other mental disorders: patients were

dosed with the hormone insulin, causing them
to go into shock and then a coma. It became

common in the 1940s and 50s. But this method
of inducing shock wasn’t alone; there were

several.
The most famous, invented in the 1930s, was

electroconvulsive treatment or ECT. Many people
have objected to ECT over the years, and the

exact way it’s been used has changed. But
today, as a treatment for severe depression,

it’s considered safe.
One pre-World War Two treatment that is no

longer used is lobotomy, or surgically cutting
connections in the brain’s prefrontal cortex.

This left patients with reduced responsiveness
and awareness. They had literal brain damage,

which could help control severe symptoms of
mental disorder.

Lobotomies became common around 1935, first
in Europe, then in the United States. Initially,

they were typical psychosurgeries, performed
in hospitals.

But in 1945, neuropsychiatrist Walter Freeman
figured out how to perform lobotomies using

an icepick. He practiced on a grapefruit at
home. And then he went on the road, popularizing

his much faster transorbital technique.
In the United States, 40,000 people were lobotomized.

Were they all suffering from severe mental
disorders, and did they enjoy better lives

after the surgery? Some probably did.
But, unfortunately, in many cases, lobotomies

were used to make patients easier to manage,
or for even worse reasons. In 1977, Congress

investigated the history of the lobotomy,
concluding that it had often been used to

harm minorities.
The biggest advancement in biomedicine at

the time was the development of antimicrobial
compounds, like Salvarsan.

In 1931, German chemists developed an effective
anti-malaria drug, mepacrine.

Allowing medics to treat soldiers with malaria
helped open up much of the world’s equatorial

regions to combat during World War Two.
Even more revolutionary, Gerhard Domagk

—a researcher working in the
same lab that synthesized mepacrine—discovered

sulfanilamide,
the first drug that broadly treated a whole

bunch of diseases caused by bacteria. He was
awarded the Nobel in 1939… which he was

forced to give back, because Nazis.
Sulfanilamide was only the first of a whole

class of antibacterial drugs, the sulfonamides,
or sulfas. These were the first antibiotics.

With them, doctors could quickly and cheaply
help thousands of patients—treating everything

from meningitis to gonorrhea to burns.
But most people today don’t go to the doctor

and ask for sulfas.
Because in 1928, in the basement laboratory

of St. Mary’s hospital in London, Scottish
physician and microbiologist Alexander Fleming

noticed, quite by accident, that some mold
growing in his lab seemed to kill some harmful

bacteria.
He cultured it and started experimenting.

Fleming discovered a whole new class of antibiotic
drugs—the penicillins—derived from that

mold, penicillium.
Alas—at first, his colleagues didn’t understand.

Fleming wasn’t great at explaining his work,
and it took him years to convince them. A

few doctors used penicillin in the 1930s.
But it wasn’t until nearly ten years later

that penicillin became a “wonder drug.”
Again, Merck scaled up production, followed

by Pfizer. And again, World War Two drove
demand.

The penicillins pretty much replaced the sulfas
during World War two, treating sexually transmitted

diseases, burns, heart infections, scarlet
fever, pneumonia, and infections of the skin,

mouth, and throat. Whole categories of disease
that had once been deadly became manageable.

This is good news for me by the way because I am allergic to sulfas as I found out

when I took one and became a giant puff.

Later drugs created based on the penicillins,

starting with ampicillin in 1961, were even
more effective against more diseases.

Fleming won the Nobel in 1945, sharing it
with two other scientists who had figured

out how to scale up production of the mold
to industrial levels—English pharmacologist

Howard Florey and German biochemist Ernst
Chain. They were all knighted.

So yay, more treatments for more diseases,
and doctors being knights. Unfortunately,

one medical pioneer was definitely not treated
with this respect. Introduce us, ThoughtBubble:

African-American surgeon Charles Drew showed

enormous promise. He graduated from medical
school at McGill University in Montreal, Canada,

in 1933 and became an instructor at Howard
University in Washington, D.C., in 1935. A

year later, he became a surgical resident
at Freedmen’s Hospital.

And in 1938, Drew earned a Rockefeller Fellowship
to study at Columbia University and work at

Presbyterian Hospital. There, he became the
first African-American doctor of medical science.

His doctoral thesis, “Banked Blood,” revolutionized
medicine.

Drew realized that blood plasma—the clear
part, without cells—lasts a lot longer than

whole blood. He worked out how to bank, or
store plasma for longer periods of time. He

also discovered that plasma can be dried and
rehydrated as needed.

Anticipating terrible casualties, and drawing

on lessons from the first World War, New York’s
Blood Transfusion Betterment Association met

with British physician John Scudder to formulate
a plan. Scudder had heard of Drew’s work

on plasma and hired him as soon as he earned
his doctorate, in 1940.

Drew’s new job was to coordinate Blood for
Britain. His team collected and processed

blood plasma from different hospitals in New
York, shipping it overseas to save Allied

lives.
A year later, Drew led another large-scale

blood project, this time for the American
Red Cross and the U.S. military. But there

was a catch: the military wanted Drew to segregate
the blood donated by African Americans from

that donated by whites. Understandably outraged,
Drew resigned after only a few months.

By the end of 1941, when Drew returned to
Howard, he had created two of the first large

blood banks. But he was not a knight, and
his country was still so deeply racist that

even its official supply of lifesaving biomaterials
was segregated.====

In 1950, Drew died in a car accident. He was
only forty five years old.

Thanks, Thoughtbubble. But this was far from
the worst offense in World War Two. The Nazis

also undertook systematic research on human
biology and medicine—all within the paradigm

of Rassenhygiene, or racial hygiene.
This was German eugenics: the application

of a distorted understanding of Darwinian
evolution to human society.

The Nazis believed that certain human groups
were better than others, and that biology—not

nurture—determined everything. But they
wanted proof.

In the 1920s, the racial hygienists had to
wait around. But with the Nazi takeover in

1933, they had the research material they
needed to understand the human body at a deep

level, in the form of Jewish people and others
whom the Nazi state didn’t consider fully

human.
During World War Two, Nazi scientists such

as Josef Mengele performed experiments on
humans in concentration camps. Among other

atrocities, Mengele conducted studies of genetics,
including twin studies, but killed subjects

afterwards, sending tissue samples back to
Berlin for further analysis.

Like the Allies, the Nazis developed drugs.
But the Nazis weren’t sure if they should

focus on antibiotics, which kill bacteria,
or on homeopathic remedies, which are based

on the idea that a substance that causes disease
in a healthy person can cure similar symptoms

in a sick person.

To conduct their tests, the Nazis simulated
brutal war injuries on concentration camp

prisoners and then tried to prevent infections
using different agents.

Finally, the Nazis developed a robust euthanasia
program, or way of testing the cheapest, fastest

ways to kill the most people without causing
them to riot.

Meanwhile, in occupied China, an infamous
group of biologists and chemists within the

Imperial Japanese Army called Unit 731 carried
out some similarly horrifying research.

They cut patients open while they were still
alive, without anesthesia. They tested new

biological weapons. They tested the limits
of human resistance to hypothermia, or frostbite.

It gets worse, but you get the idea.
When the war ended, the United States government

discovered the atrocities committed by the
Imperial Japanese doctors… And they cut

a deal: the U.S. would grant certain war criminals
immunity in exchange for their data.

So where’s the goodness I talked about at the beginning of the episode? Well, after
World War Two, more drugs, medical technologies,

and novel procedures emerged. For example,
in the 1950s, Jonas Salk and A. B. Sabin created

a polio vaccine, which was very good!
But the deeper point is that medicine—now

a global institution—had a long look at
itself. The vast majority of doctors and government

officials were absolutely sickened by the
revelations of the Doctors’ Trial of the

Nazis.
Doctors convened and created a new way of

handling medical research with human subjects,
the Nuremberg Code of medical ethics. In fact,

a whole new branch of philosophy, bioethics
was born.

On the policy side, all human subjects research
in the U.S. now has to be approved by institutional

review boards or IRBs. It’s a long process
in which scientists and regulators scrutinize

what will or won’t be done in the name of
medicine, to whom, for what purpose. And it’s

one of the greatest, quietest moral wins in
the history of science.

Next time—we finally bring together Darwin
and Mendel in an intellectual super-group

called the Modern Synthesis. Don’t miss
it!

Crash Course History of Science is filmed
in the Dr. Cheryl C. Kinney studio in Missoula,

Montana and it’s made with the help of all
this nice people and our animation team is

Thought Cafe.
Crash Course is a Complexly production. If

you wanna keep imagining the world complexly
with us, you can check out some of our other

channels like Scishow, Nature League, and The Financial Diet.

And, if you’d like to keep Crash Course
free for everybody, forever, you can support

the series at Patreon; a crowdfunding platform
that allows you to support the content you

love. Thank you to all of our patrons for
making Crash Course possible with their continued

support.

